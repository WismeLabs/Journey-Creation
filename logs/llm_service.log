2025-11-16 00:25:17,567 - main - ERROR - GEMINI_API_KEY not found in environment
2025-11-16 00:25:17,568 - main - ERROR - Regeneration failed for regen_tone_fix: 500: Gemini API not configured
2025-11-16 00:28:30,243 - main - ERROR - GEMINI_API_KEY not found in environment
2025-11-16 00:28:30,244 - main - ERROR - Concept extraction failed: 500: Gemini API not configured
2025-11-16 00:28:30,265 - main - ERROR - GEMINI_API_KEY not found in environment
2025-11-16 00:28:30,265 - main - ERROR - Script generation failed: 500: Gemini API not configured
2025-11-16 00:28:30,272 - main - ERROR - GEMINI_API_KEY not found in environment
2025-11-16 00:28:30,272 - main - ERROR - Regeneration failed for regen_tone_fix: 500: Gemini API not configured
2025-11-16 00:32:03,313 - main - WARNING - GEMINI_API_KEY not found - using mock mode for development
2025-11-16 00:32:03,314 - main - INFO - Using mock concept extraction for development
2025-11-16 00:32:29,423 - main - WARNING - GEMINI_API_KEY not found - using mock mode for development
2025-11-16 00:32:29,424 - main - INFO - Using mock concept extraction for development
2025-11-16 00:32:29,425 - main - WARNING - GEMINI_API_KEY not found - using mock mode for development
2025-11-16 00:32:29,426 - main - INFO - Using mock script generation for development
2025-11-16 00:33:50,593 - main - WARNING - GEMINI_API_KEY not found - using mock mode for development
2025-11-16 00:33:50,593 - main - INFO - Using mock concept extraction for development
2025-11-16 00:33:50,615 - main - WARNING - GEMINI_API_KEY not found - using mock mode for development
2025-11-16 00:33:50,615 - main - INFO - Using mock script generation for development
2025-11-16 00:33:50,618 - main - WARNING - GEMINI_API_KEY not found - using mock mode for development
2025-11-16 00:33:50,618 - main - INFO - Generating 3 MCQs
2025-11-16 00:33:50,618 - main - ERROR - MCQ generation failed: 'str' object has no attribute 'generate_content'
2025-11-16 00:33:50,624 - main - WARNING - GEMINI_API_KEY not found - using mock mode for development
2025-11-16 00:33:50,624 - main - INFO - Running regeneration prompt: regen_tone_fix
2025-11-16 00:33:50,624 - main - ERROR - Regeneration failed for regen_tone_fix: 'str' object has no attribute 'generate_content'
2025-11-16 00:35:53,530 - main - WARNING - GEMINI_API_KEY not found - using mock mode for development
2025-11-16 00:35:53,531 - main - INFO - Using mock MCQ generation for development
2025-11-16 00:40:04,797 - main - WARNING - GEMINI_API_KEY not found - using mock mode for development
2025-11-16 00:40:04,797 - main - INFO - Using mock MCQ generation for development
2025-11-16 00:40:17,792 - main - WARNING - GEMINI_API_KEY not found - using mock mode for development
2025-11-16 00:40:17,792 - main - INFO - Using mock MCQ generation for development
2025-11-17 22:52:55,227 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 22:52:55,238 - __main__ - INFO - [OK] LLM Service started successfully - all systems operational
2025-11-17 23:06:02,557 - __main__ - INFO - [SHUTDOWN] LLM Service shutting down
2025-11-17 23:06:15,117 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:06:15,118 - __main__ - INFO - [OK] LLM Service started successfully - all systems operational
2025-11-17 23:07:14,529 - __main__ - INFO - [SHUTDOWN] LLM Service shutting down
2025-11-17 23:07:24,936 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:07:24,937 - __main__ - INFO - [OK] LLM Service started successfully - all systems operational
2025-11-17 23:07:46,032 - __main__ - INFO - [SHUTDOWN] LLM Service shutting down
2025-11-17 23:12:01,622 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:12:01,623 - __main__ - INFO - [OK] LLM Service started successfully - all systems operational
2025-11-17 23:12:33,540 - __main__ - INFO - [SHUTDOWN] LLM Service shutting down
2025-11-17 23:12:43,230 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:12:43,231 - __main__ - INFO - [OK] LLM Service started successfully - all systems operational
2025-11-17 23:13:23,002 - __main__ - INFO - [SHUTDOWN] LLM Service shutting down
2025-11-17 23:16:26,012 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:16:26,014 - __main__ - INFO - [OK] LLM Service started successfully - all systems operational
2025-11-17 23:17:03,117 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:18:56,391 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:20:09,753 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:20:33,985 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:20:35,059 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:20:35,060 - __main__ - INFO - Extracting concepts for Science content using Gemini API
2025-11-17 23:20:38,290 - __main__ - INFO - Successfully extracted 4 concepts
2025-11-17 23:20:39,208 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:20:39,208 - __main__ - INFO - Generating script for episode: Science - Episode 1 using Gemini API
2025-11-17 23:20:48,112 - __main__ - INFO - Successfully generated script with 6 sections
2025-11-17 23:20:49,035 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:20:49,036 - __main__ - INFO - Generating 3 MCQs using Gemini API
2025-11-17 23:20:49,037 - __main__ - ERROR - MCQ generation failed: 'speaker1_name'
2025-11-17 23:20:49,969 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:20:49,971 - __main__ - INFO - Running regeneration prompt: regen_tone_fix
2025-11-17 23:20:51,588 - __main__ - INFO - Successfully completed regeneration: regen_tone_fix
2025-11-17 23:20:52,387 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:20:52,387 - __main__ - INFO - Generating script for episode: Science - Episode 2 using Gemini API
2025-11-17 23:21:02,555 - __main__ - INFO - Successfully generated script with 6 sections
2025-11-17 23:21:03,631 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:21:03,632 - __main__ - INFO - Generating 1 MCQs using Gemini API
2025-11-17 23:21:03,633 - __main__ - ERROR - MCQ generation failed: 'speaker1_name'
2025-11-17 23:21:04,691 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:21:04,693 - __main__ - INFO - Running regeneration prompt: regen_tone_fix
2025-11-17 23:21:06,313 - __main__ - INFO - Successfully completed regeneration: regen_tone_fix
2025-11-17 23:21:14,639 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:21:15,692 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:21:15,693 - __main__ - INFO - Extracting concepts for Science content using Gemini API
2025-11-17 23:21:19,372 - __main__ - INFO - Successfully extracted 5 concepts
2025-11-17 23:21:20,396 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:21:20,396 - __main__ - INFO - Generating script for episode: Science - Episode 1 using Gemini API
2025-11-17 23:21:28,960 - __main__ - INFO - Successfully generated script with 6 sections
2025-11-17 23:21:29,895 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:21:29,896 - __main__ - INFO - Generating 1 MCQs using Gemini API
2025-11-17 23:21:29,896 - __main__ - ERROR - MCQ generation failed: 'speaker1_name'
2025-11-17 23:21:31,058 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:21:31,059 - __main__ - INFO - Running regeneration prompt: regen_tone_fix
2025-11-17 23:21:32,517 - __main__ - INFO - Successfully completed regeneration: regen_tone_fix
2025-11-17 23:21:32,829 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 27
}
]
2025-11-17 23:21:32,830 - __main__ - ERROR - Script generation failed: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 27
}
]
2025-11-17 23:21:32,982 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 27
}
]
2025-11-17 23:21:32,985 - __main__ - ERROR - Regeneration failed for regen_tone_fix: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 27
}
]
2025-11-17 23:21:33,280 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 26
}
]
2025-11-17 23:21:33,281 - __main__ - ERROR - Script generation failed: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 26
}
]
2025-11-17 23:21:33,599 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 26
}
]
2025-11-17 23:21:33,601 - __main__ - ERROR - Regeneration failed for regen_tone_fix: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 26
}
]
2025-11-17 23:21:33,919 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 26
}
]
2025-11-17 23:21:33,919 - __main__ - ERROR - Script generation failed: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 26
}
]
2025-11-17 23:21:34,190 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 25
}
]
2025-11-17 23:21:34,192 - __main__ - ERROR - Regeneration failed for regen_tone_fix: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 25
}
]
2025-11-17 23:21:34,515 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 25
}
]
2025-11-17 23:21:34,515 - __main__ - ERROR - Script generation failed: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 25
}
]
2025-11-17 23:21:34,816 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 25
}
]
2025-11-17 23:21:34,817 - __main__ - ERROR - Regeneration failed for regen_tone_fix: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 25
}
]
2025-11-17 23:22:54,680 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:25:40,021 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:28:37,978 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:28:39,085 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:28:39,085 - __main__ - INFO - Extracting concepts for Science content using Gemini API
2025-11-17 23:28:42,763 - __main__ - INFO - Successfully extracted 4 concepts
2025-11-17 23:28:43,829 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:28:43,829 - __main__ - INFO - Generating script for episode: Science - Episode 1 using Gemini API
2025-11-17 23:28:52,722 - __main__ - INFO - Successfully generated script with 6 sections
2025-11-17 23:28:53,807 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:28:53,808 - __main__ - INFO - Generating 3 MCQs using Gemini API
2025-11-17 23:28:53,809 - __main__ - ERROR - MCQ generation failed: 'speaker1_name'
2025-11-17 23:28:54,780 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:28:54,780 - __main__ - INFO - Running regeneration prompt: regen_tone_fix
2025-11-17 23:28:55,898 - __main__ - INFO - Successfully completed regeneration: regen_tone_fix
2025-11-17 23:28:56,862 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:28:56,863 - __main__ - INFO - Generating script for episode: Science - Episode 2 using Gemini API
2025-11-17 23:29:05,321 - __main__ - INFO - Successfully generated script with 6 sections
2025-11-17 23:29:06,289 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:29:06,290 - __main__ - INFO - Generating 1 MCQs using Gemini API
2025-11-17 23:29:06,290 - __main__ - ERROR - MCQ generation failed: 'speaker1_name'
2025-11-17 23:29:07,383 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:29:07,384 - __main__ - INFO - Running regeneration prompt: regen_tone_fix
2025-11-17 23:29:09,764 - __main__ - INFO - Successfully completed regeneration: regen_tone_fix
2025-11-17 23:34:00,737 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:34:00,738 - __main__ - INFO - [OK] LLM Service started successfully - all systems operational
2025-11-17 23:35:22,749 - __main__ - INFO - [SHUTDOWN] LLM Service shutting down
2025-11-17 23:36:34,800 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:36:34,800 - __main__ - INFO - [OK] LLM Service started successfully - all systems operational
2025-11-17 23:36:47,145 - __main__ - INFO - [SHUTDOWN] LLM Service shutting down
2025-11-17 23:37:05,051 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:37:05,054 - __main__ - INFO - [OK] LLM Service started successfully - all systems operational
2025-11-17 23:37:21,432 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:40:56,789 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:40:58,107 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:40:58,110 - __main__ - INFO - Extracting concepts for Science content using Gemini API
2025-11-17 23:41:02,644 - __main__ - INFO - Successfully extracted 5 concepts
2025-11-17 23:41:03,708 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:41:03,709 - __main__ - INFO - Generating script for episode: Science - Episode 1 using Gemini API
2025-11-17 23:41:12,124 - __main__ - INFO - Successfully generated script with 6 sections
2025-11-17 23:41:13,056 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:41:13,058 - __main__ - INFO - Generating 1 MCQs using Gemini API
2025-11-17 23:41:14,810 - __main__ - INFO - Successfully generated 1 MCQs
2025-11-17 23:41:15,871 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:41:15,873 - __main__ - INFO - Running regeneration prompt: regen_mcq_sync
2025-11-17 23:41:21,464 - __main__ - INFO - Successfully completed regeneration: regen_mcq_sync
2025-11-17 23:41:22,259 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:41:22,261 - __main__ - INFO - Running regeneration prompt: regen_remove_hallucination
2025-11-17 23:41:28,098 - __main__ - INFO - Successfully completed regeneration: regen_remove_hallucination
2025-11-17 23:41:28,905 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:41:28,905 - __main__ - INFO - Running regeneration prompt: regen_dedup
2025-11-17 23:41:45,068 - __main__ - INFO - Successfully completed regeneration: regen_dedup
2025-11-17 23:41:45,850 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-17 23:41:45,850 - __main__ - INFO - Running regeneration prompt: regen_tone_fix
2025-11-17 23:41:45,956 - __main__ - ERROR - Regeneration failed for regen_tone_fix: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 14
}
]
2025-11-17 23:41:46,269 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 13
}
]
2025-11-17 23:41:46,270 - __main__ - ERROR - Regeneration failed for regen_remove_hallucination: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 13
}
]
2025-11-17 23:41:46,592 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 13
}
]
2025-11-17 23:41:46,592 - __main__ - ERROR - Regeneration failed for regen_tone_fix: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 13
}
]
2025-11-17 23:41:46,747 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 13
}
]
2025-11-17 23:41:46,749 - __main__ - ERROR - Script generation failed: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 13
}
]
2025-11-17 23:41:47,058 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 12
}
]
2025-11-17 23:41:47,059 - __main__ - ERROR - Regeneration failed for regen_tone_fix: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 12
}
]
2025-11-17 23:41:47,212 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 12
}
]
2025-11-17 23:41:47,212 - __main__ - ERROR - Script generation failed: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 12
}
]
2025-11-17 23:41:47,509 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 12
}
]
2025-11-17 23:41:47,510 - __main__ - ERROR - Regeneration failed for regen_tone_fix: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 12
}
]
2025-11-17 23:41:47,828 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 12
}
]
2025-11-17 23:41:47,829 - __main__ - ERROR - Script generation failed: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 12
}
]
2025-11-17 23:41:48,132 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 11
}
]
2025-11-17 23:41:48,133 - __main__ - ERROR - Regeneration failed for regen_tone_fix: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 11
}
]
2025-11-17 23:41:48,459 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 11
}
]
2025-11-17 23:41:48,460 - __main__ - ERROR - Script generation failed: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 11
}
]
2025-11-17 23:41:48,763 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 11
}
]
2025-11-17 23:41:48,764 - __main__ - ERROR - Regeneration failed for regen_tone_fix: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 11
}
]
2025-11-20 06:00:21,131 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-20 06:00:21,131 - __main__ - INFO - [OK] LLM Service started successfully - all systems operational
2025-11-20 06:24:54,235 - __main__ - INFO - [SHUTDOWN] LLM Service shutting down
2025-11-20 06:25:00,776 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-20 06:25:00,777 - __main__ - INFO - [OK] LLM Service started successfully - all systems operational
2025-11-20 06:27:23,943 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-20 06:27:23,943 - __main__ - INFO - Extracting concepts for Science content using Gemini API
2025-11-20 06:27:28,868 - __main__ - INFO - Successfully extracted 6 concepts
2025-11-20 06:27:29,608 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-20 06:27:29,608 - __main__ - INFO - Generating script for episode: Science - Episode 1 using Gemini API
2025-11-20 06:27:37,644 - __main__ - INFO - Successfully generated script with 6 sections
2025-11-20 06:27:38,704 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-20 06:27:38,705 - __main__ - INFO - Generating 1 MCQs using Gemini API
2025-11-20 06:27:42,643 - __main__ - INFO - Successfully generated 3 MCQs
2025-11-20 06:27:43,714 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-20 06:27:43,715 - __main__ - INFO - Running regeneration prompt: regen_mcq_sync
2025-11-20 06:27:48,962 - __main__ - INFO - Successfully completed regeneration: regen_mcq_sync
2025-11-20 06:27:49,896 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-20 06:27:49,897 - __main__ - INFO - Running regeneration prompt: regen_remove_hallucination
2025-11-20 06:27:56,241 - __main__ - INFO - Successfully completed regeneration: regen_remove_hallucination
2025-11-20 06:27:57,197 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-20 06:27:57,198 - __main__ - INFO - Running regeneration prompt: regen_dedup
2025-11-20 06:27:57,305 - __main__ - ERROR - Regeneration failed for regen_dedup: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 3
}
]
2025-11-20 06:27:57,637 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 2
}
]
2025-11-20 06:27:57,637 - __main__ - ERROR - Regeneration failed for regen_tone_fix: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 2
}
]
2025-11-20 06:27:57,956 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 2
}
]
2025-11-20 06:27:57,957 - __main__ - ERROR - Regeneration failed for regen_remove_hallucination: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 2
}
]
2025-11-20 06:27:58,303 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 2
}
]
2025-11-20 06:27:58,304 - __main__ - ERROR - Regeneration failed for regen_tone_fix: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 2
}
]
2025-11-20 06:27:58,611 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 1
}
]
2025-11-20 06:27:58,611 - __main__ - ERROR - Script generation failed: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 1
}
]
2025-11-20 06:27:58,918 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 1
}
]
2025-11-20 06:27:58,919 - __main__ - ERROR - Regeneration failed for regen_tone_fix: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 1
}
]
2025-11-20 06:27:59,229 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 1
}
]
2025-11-20 06:27:59,230 - __main__ - ERROR - Script generation failed: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 1
}
]
2025-11-20 06:28:00,153 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-20 06:28:00,153 - __main__ - INFO - Running regeneration prompt: regen_tone_fix
2025-11-20 06:28:01,214 - __main__ - INFO - Successfully completed regeneration: regen_tone_fix
2025-11-20 06:28:01,967 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-20 06:28:01,967 - __main__ - INFO - Generating script for episode: Science - Episode 4 using Gemini API
2025-11-20 06:28:09,889 - __main__ - INFO - Successfully generated script with 6 sections
2025-11-20 06:28:10,839 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-20 06:28:10,840 - __main__ - INFO - Generating 1 MCQs using Gemini API
2025-11-20 06:28:12,775 - __main__ - INFO - Successfully generated 1 MCQs
2025-11-20 06:28:13,760 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-20 06:28:13,761 - __main__ - INFO - Running regeneration prompt: regen_mcq_sync
2025-11-20 06:28:17,800 - __main__ - INFO - Successfully completed regeneration: regen_mcq_sync
2025-11-20 06:28:18,854 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-20 06:28:18,855 - __main__ - INFO - Running regeneration prompt: regen_remove_hallucination
2025-11-20 06:28:27,258 - __main__ - INFO - Successfully completed regeneration: regen_remove_hallucination
2025-11-20 06:28:28,255 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-20 06:28:28,255 - __main__ - INFO - Running regeneration prompt: regen_dedup
2025-11-20 06:28:28,354 - __main__ - ERROR - Regeneration failed for regen_dedup: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 32
}
]
2025-11-20 06:28:28,686 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 31
}
]
2025-11-20 06:28:28,687 - __main__ - ERROR - Regeneration failed for regen_tone_fix: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 31
}
]
2025-11-20 06:28:29,005 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 31
}
]
2025-11-20 06:28:29,006 - __main__ - ERROR - Regeneration failed for regen_remove_hallucination: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 31
}
]
2025-11-20 06:28:29,300 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 31
}
]
2025-11-20 06:28:29,300 - __main__ - ERROR - Regeneration failed for regen_tone_fix: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 31
}
]
2025-11-20 06:28:29,598 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 30
}
]
2025-11-20 06:28:29,598 - __main__ - ERROR - Script generation failed: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 30
}
]
2025-11-20 06:28:29,907 - __main__ - ERROR - [ERROR] Gemini API setup failed: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 30
}
]
2025-11-20 06:28:29,907 - __main__ - ERROR - Regeneration failed for regen_tone_fix: 500: Gemini API configuration error: 429 You exceeded your current quota. Please migrate to Gemini 2.0 Flash Preview (Image Generation) (models/gemini-2.0-flash-preview-image-generation) for higher quota limits. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_requests_per_model"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash-exp"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 10
}
, retry_delay {
  seconds: 30
}
]
2025-11-20 06:36:11,034 - __main__ - INFO - [SHUTDOWN] LLM Service shutting down
2025-11-20 06:39:22,283 - __main__ - ERROR - [ERROR] Gemini API setup failed: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.
2025-11-20 06:39:22,284 - __main__ - ERROR - [WARNING] Startup validation failed - service may not function correctly: 500: Gemini API configuration error: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.
2025-11-20 06:39:46,901 - __main__ - INFO - [SHUTDOWN] LLM Service shutting down
2025-11-22 14:02:30,832 - __main__ - INFO - [AUTO MODE] Primary: OpenAI GPT-4o | Fallback: Gemini 2.0 Flash
2025-11-22 14:02:31,071 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-22 14:02:31,428 - __main__ - ERROR - [ERROR] Gemini API setup failed: 400 API key not valid. Please pass a valid API key. [reason: "API_KEY_INVALID"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
, locale: "en-US"
message: "API key not valid. Please pass a valid API key."
]
2025-11-22 14:02:31,429 - __main__ - ERROR - [WARNING] Startup validation failed - service may not function correctly: 500: Gemini API configuration error: 400 API key not valid. Please pass a valid API key. [reason: "API_KEY_INVALID"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
, locale: "en-US"
message: "API key not valid. Please pass a valid API key."
]
2025-11-22 14:05:25,649 - __main__ - INFO - [SHUTDOWN] LLM Service shutting down
2025-11-22 21:11:04,514 - __main__ - INFO - [AUTO MODE] Primary: OpenAI GPT-4o | Fallback: Gemini 2.0 Flash
2025-11-22 21:11:04,803 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-22 21:11:05,186 - __main__ - ERROR - [ERROR] Gemini API setup failed: 400 API key not valid. Please pass a valid API key. [reason: "API_KEY_INVALID"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
, locale: "en-US"
message: "API key not valid. Please pass a valid API key."
]
2025-11-22 21:11:05,186 - __main__ - ERROR - [WARNING] Startup validation failed - service may not function correctly: 500: Gemini API configuration error: 400 API key not valid. Please pass a valid API key. [reason: "API_KEY_INVALID"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
, locale: "en-US"
message: "API key not valid. Please pass a valid API key."
]
2025-11-22 21:18:51,077 - __main__ - INFO - [SHUTDOWN] LLM Service shutting down
2025-11-24 15:16:08,973 - __main__ - INFO - [AUTO MODE] Primary: OpenAI GPT-4o | Fallback: Gemini 2.0 Flash
2025-11-24 15:16:09,206 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-24 15:16:10,246 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-24 15:16:10,246 - __main__ - INFO - [OK] All systems operational
2025-11-24 15:23:50,769 - __main__ - INFO - [AUTO MODE] Primary: OpenAI GPT-4o | Fallback: Gemini 2.0 Flash
2025-11-24 15:23:51,006 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-24 15:23:51,963 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-24 15:23:51,963 - __main__ - INFO - [OK] All systems operational
2025-11-24 15:36:01,380 - main - INFO - [AUTO MODE] Primary: OpenAI GPT-4o | Fallback: Gemini 2.0 Flash
2025-11-24 15:36:01,545 - main - INFO - [OK] OpenAI API configured successfully
2025-11-24 15:36:02,509 - main - INFO - [OK] Gemini API configured and validated successfully
2025-11-24 15:36:02,510 - main - INFO - [OK] All systems operational
2025-11-24 15:36:22,140 - main - INFO - [SHUTDOWN] LLM Service shutting down
2025-11-24 15:36:33,183 - main - INFO - [AUTO MODE] Primary: OpenAI GPT-4o | Fallback: Gemini 2.0 Flash
2025-11-24 15:36:33,333 - main - INFO - [OK] OpenAI API configured successfully
2025-11-24 15:36:34,295 - main - INFO - [OK] Gemini API configured and validated successfully
2025-11-24 15:36:34,295 - main - INFO - [OK] All systems operational
2025-11-24 15:49:30,831 - __main__ - INFO - [AUTO MODE] Primary: OpenAI GPT-4o | Fallback: Gemini 2.0 Flash
2025-11-24 15:49:30,977 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-24 15:49:32,016 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-24 15:49:32,017 - __main__ - INFO - [OK] All systems operational
2025-11-25 20:04:00,041 - __main__ - INFO - [AUTO MODE] Primary: OpenAI GPT-4o | Fallback: Gemini 2.0 Flash
2025-11-25 20:04:00,200 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-25 20:04:01,299 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-25 20:04:01,300 - __main__ - INFO - [OK] All systems operational
2025-11-25 20:16:42,632 - __main__ - INFO - [SHUTDOWN] LLM Service shutting down
2025-11-26 16:24:49,547 - __main__ - INFO - [AUTO MODE] Primary: OpenAI GPT-4o | Fallback: Gemini 2.0 Flash
2025-11-26 16:24:49,797 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:24:50,853 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-26 16:24:50,853 - __main__ - INFO - [OK] All systems operational
2025-11-26 16:31:45,255 - __main__ - INFO - [SHUTDOWN] LLM Service shutting down
2025-11-26 16:33:54,983 - __main__ - INFO - [AUTO MODE] Primary: OpenAI GPT-4o | Fallback: Gemini 2.0 Flash
2025-11-26 16:33:55,216 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:33:56,299 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-26 16:33:56,300 - __main__ - INFO - [OK] All systems operational
2025-11-26 16:38:44,367 - __main__ - INFO - Job concept_extraction_1764155324_505bc08f: processing
2025-11-26 16:38:44,369 - __main__ - INFO - [concept_extraction_1764155324_505bc08f] Extracting concepts for Science content using OPENAI
2025-11-26 16:38:45,551 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:38:45,552 - __main__ - INFO - [OpenAI] Trying model: gpt-5.1
2025-11-26 16:38:48,626 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-26 16:38:48,630 - __main__ - WARNING - [OpenAI] gpt-5.1 via chat.completions failed: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with t
2025-11-26 16:38:48,895 - __main__ - WARNING - [OpenAI] gpt-5.1 via responses API also failed: AsyncResponses.create() got an unexpected keyword argument 'response_format'
2025-11-26 16:38:48,896 - __main__ - WARNING -  OpenAI (gpt-5.1): Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 
2025-11-26 16:38:50,113 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:38:50,114 - __main__ - INFO - [OpenAI] Trying model: gpt-4o
2025-11-26 16:39:06,109 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-26 16:39:06,117 - __main__ - INFO -  Successfully generated content using OpenAI (gpt-4o)
2025-11-26 16:39:06,118 - __main__ - INFO - [concept_extraction_1764155324_505bc08f] Successfully extracted 5 concepts
2025-11-26 16:39:06,118 - __main__ - INFO - Job concept_extraction_1764155324_505bc08f: completed
2025-11-26 16:39:06,138 - __main__ - INFO - Job script_generation_1764155346_3ebdce59: processing
2025-11-26 16:39:06,139 - __main__ - INFO - [script_generation_1764155346_3ebdce59] Generating script for episode: Science - Episode 1 using OPENAI
2025-11-26 16:39:06,296 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:39:06,297 - __main__ - INFO - [OpenAI] Trying model: gpt-5.1
2025-11-26 16:39:06,299 - __main__ - INFO - Job script_generation_1764155346_c40072d5: processing
2025-11-26 16:39:06,300 - __main__ - INFO - [script_generation_1764155346_c40072d5] Generating script for episode: Science - Episode 2 using OPENAI
2025-11-26 16:39:06,459 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:39:06,459 - __main__ - INFO - [OpenAI] Trying model: gpt-5.1
2025-11-26 16:39:07,505 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-26 16:39:07,506 - __main__ - WARNING - [OpenAI] gpt-5.1 via chat.completions failed: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with t
2025-11-26 16:39:07,506 - __main__ - WARNING - [OpenAI] gpt-5.1 via responses API also failed: AsyncResponses.create() got an unexpected keyword argument 'response_format'
2025-11-26 16:39:07,507 - __main__ - WARNING -  OpenAI (gpt-5.1): Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 
2025-11-26 16:39:07,668 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:39:07,669 - __main__ - INFO - [OpenAI] Trying model: gpt-4o
2025-11-26 16:39:07,686 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-26 16:39:07,686 - __main__ - WARNING - [OpenAI] gpt-5.1 via chat.completions failed: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with t
2025-11-26 16:39:07,687 - __main__ - WARNING - [OpenAI] gpt-5.1 via responses API also failed: AsyncResponses.create() got an unexpected keyword argument 'response_format'
2025-11-26 16:39:07,687 - __main__ - WARNING -  OpenAI (gpt-5.1): Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 
2025-11-26 16:39:07,847 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:39:07,848 - __main__ - INFO - [OpenAI] Trying model: gpt-4o
2025-11-26 16:39:22,557 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-26 16:39:22,565 - __main__ - INFO -  Successfully generated content using OpenAI (gpt-4o)
2025-11-26 16:39:22,565 - __main__ - INFO - [script_generation_1764155346_3ebdce59] Successfully generated script with 2 sections
2025-11-26 16:39:22,565 - __main__ - INFO - Job script_generation_1764155346_3ebdce59: completed
2025-11-26 16:39:22,568 - __main__ - INFO - Job mcq_generation_1764155362_3ff0b6da: processing
2025-11-26 16:39:22,568 - __main__ - INFO - [mcq_generation_1764155362_3ff0b6da] Generating 6 MCQs using OPENAI
2025-11-26 16:39:22,733 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:39:22,733 - __main__ - INFO - [OpenAI] Trying model: gpt-5.1
2025-11-26 16:39:23,824 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-26 16:39:23,825 - __main__ - WARNING - [OpenAI] gpt-5.1 via chat.completions failed: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with t
2025-11-26 16:39:23,825 - __main__ - WARNING - [OpenAI] gpt-5.1 via responses API also failed: AsyncResponses.create() got an unexpected keyword argument 'response_format'
2025-11-26 16:39:23,826 - __main__ - WARNING -  OpenAI (gpt-5.1): Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 
2025-11-26 16:39:23,987 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:39:23,988 - __main__ - INFO - [OpenAI] Trying model: gpt-4o
2025-11-26 16:39:26,792 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-26 16:39:26,799 - __main__ - INFO -  Successfully generated content using OpenAI (gpt-4o)
2025-11-26 16:39:26,800 - __main__ - INFO - [script_generation_1764155346_c40072d5] Successfully generated script with 2 sections
2025-11-26 16:39:26,800 - __main__ - INFO - Job script_generation_1764155346_c40072d5: completed
2025-11-26 16:39:26,802 - __main__ - INFO - Job mcq_generation_1764155366_4b430464: processing
2025-11-26 16:39:26,802 - __main__ - INFO - [mcq_generation_1764155366_4b430464] Generating 3 MCQs using OPENAI
2025-11-26 16:39:26,967 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:39:26,967 - __main__ - INFO - [OpenAI] Trying model: gpt-5.1
2025-11-26 16:39:28,031 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:39:28,031 - openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2025-11-26 16:39:38,687 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-26 16:39:38,701 - __main__ - INFO -  Successfully generated content using OpenAI (gpt-4o)
2025-11-26 16:39:38,701 - __main__ - INFO - [mcq_generation_1764155362_3ff0b6da] Successfully generated 6 MCQs
2025-11-26 16:39:38,701 - __main__ - INFO - Job mcq_generation_1764155362_3ff0b6da: completed
2025-11-26 16:39:38,718 - __main__ - INFO - Job regenerate_1764155378_a4c38e01: processing
2025-11-26 16:39:38,718 - __main__ - INFO - [regenerate_1764155378_a4c38e01] Running regeneration prompt: regen_mcq_sync using OPENAI
2025-11-26 16:39:38,880 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:39:38,880 - __main__ - INFO - [OpenAI] Trying model: gpt-5.1
2025-11-26 16:39:39,265 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-26 16:39:39,267 - __main__ - WARNING - [OpenAI] gpt-5.1 via chat.completions failed: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with t
2025-11-26 16:39:39,267 - __main__ - WARNING - [OpenAI] gpt-5.1 via responses API also failed: AsyncResponses.create() got an unexpected keyword argument 'response_format'
2025-11-26 16:39:39,267 - __main__ - WARNING -  OpenAI (gpt-5.1): Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 
2025-11-26 16:39:39,430 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:39:39,431 - __main__ - INFO - [OpenAI] Trying model: gpt-4o
2025-11-26 16:39:48,354 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:39:48,355 - openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2025-11-26 16:39:48,621 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-26 16:39:48,622 - __main__ - INFO -  Successfully generated content using OpenAI (gpt-4o)
2025-11-26 16:39:48,623 - __main__ - INFO - [regenerate_1764155378_a4c38e01] Successfully completed regeneration: regen_mcq_sync
2025-11-26 16:39:48,623 - __main__ - INFO - Job regenerate_1764155378_a4c38e01: completed
2025-11-26 16:39:48,634 - __main__ - INFO - Job regenerate_1764155388_87609edb: processing
2025-11-26 16:39:48,634 - __main__ - INFO - [regenerate_1764155388_87609edb] Running regeneration prompt: regen_remove_hallucination using OPENAI
2025-11-26 16:39:48,796 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:39:48,796 - __main__ - INFO - [OpenAI] Trying model: gpt-5.1
2025-11-26 16:39:49,177 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-26 16:39:49,178 - __main__ - WARNING - [OpenAI] gpt-5.1 via chat.completions failed: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with t
2025-11-26 16:39:49,179 - __main__ - WARNING - [OpenAI] gpt-5.1 via responses API also failed: AsyncResponses.create() got an unexpected keyword argument 'response_format'
2025-11-26 16:39:49,179 - __main__ - WARNING -  OpenAI (gpt-5.1): Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 
2025-11-26 16:39:49,343 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:39:49,343 - __main__ - INFO - [OpenAI] Trying model: gpt-4o
2025-11-26 16:39:49,673 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:39:49,674 - openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2025-11-26 16:40:08,722 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-26 16:40:08,725 - __main__ - WARNING - [OpenAI] gpt-5.1 via chat.completions failed: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with t
2025-11-26 16:40:08,725 - __main__ - WARNING - [OpenAI] gpt-5.1 via responses API also failed: AsyncResponses.create() got an unexpected keyword argument 'response_format'
2025-11-26 16:40:08,726 - __main__ - WARNING -  OpenAI (gpt-5.1): Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 
2025-11-26 16:40:09,893 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:40:09,896 - __main__ - INFO - [OpenAI] Trying model: gpt-4o
2025-11-26 16:40:17,719 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-26 16:40:17,725 - __main__ - INFO -  Successfully generated content using OpenAI (gpt-4o)
2025-11-26 16:40:17,726 - __main__ - INFO - [regenerate_1764155388_87609edb] Successfully completed regeneration: regen_remove_hallucination
2025-11-26 16:40:17,728 - __main__ - INFO - Job regenerate_1764155388_87609edb: completed
2025-11-26 16:40:17,744 - __main__ - INFO - Job regenerate_1764155417_f7979abf: processing
2025-11-26 16:40:17,746 - __main__ - INFO - [regenerate_1764155417_f7979abf] Running regeneration prompt: regen_simplify_vocabulary using OPENAI
2025-11-26 16:40:18,944 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:40:18,945 - __main__ - INFO - [OpenAI] Trying model: gpt-5.1
2025-11-26 16:40:19,292 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:40:19,293 - openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2025-11-26 16:40:19,589 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-26 16:40:19,600 - __main__ - INFO -  Successfully generated content using OpenAI (gpt-4o)
2025-11-26 16:40:19,600 - __main__ - INFO - [mcq_generation_1764155366_4b430464] Successfully generated 3 MCQs
2025-11-26 16:40:19,603 - __main__ - INFO - Job mcq_generation_1764155366_4b430464: completed
2025-11-26 16:40:19,623 - __main__ - INFO - Job regenerate_1764155419_a4c38e01: processing
2025-11-26 16:40:19,623 - __main__ - INFO - [regenerate_1764155419_a4c38e01] Running regeneration prompt: regen_mcq_sync using OPENAI
2025-11-26 16:40:20,809 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:40:20,809 - __main__ - INFO - [OpenAI] Trying model: gpt-5.1
2025-11-26 16:40:21,142 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:40:21,143 - openai._base_client - INFO - Retrying request to /chat/completions in 2.850000 seconds
2025-11-26 16:40:24,291 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:40:24,292 - openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2025-11-26 16:40:39,650 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:40:39,651 - openai._base_client - INFO - Retrying request to /chat/completions in 5.070000 seconds
2025-11-26 16:40:44,607 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:40:44,608 - __main__ - WARNING - [OpenAI] gpt-5.1 via chat.completions failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-5.1 in organization org-hnKFObux
2025-11-26 16:40:44,608 - __main__ - WARNING - [OpenAI] gpt-5.1 via responses API also failed: AsyncResponses.create() got an unexpected keyword argument 'response_format'
2025-11-26 16:40:44,608 - __main__ - WARNING -  OpenAI (gpt-5.1): Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-5.1 in organization org-hnKFObuxgiWnOQU9Y1DqflGF on requests per min (RPM): Limit 
2025-11-26 16:40:44,772 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:40:44,772 - __main__ - INFO - [OpenAI] Trying model: gpt-4o
2025-11-26 16:40:45,112 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:40:45,113 - __main__ - WARNING - [OpenAI] gpt-5.1 via chat.completions failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-5.1 in organization org-hnKFObux
2025-11-26 16:40:45,113 - __main__ - WARNING - [OpenAI] gpt-5.1 via responses API also failed: AsyncResponses.create() got an unexpected keyword argument 'response_format'
2025-11-26 16:40:45,113 - __main__ - WARNING -  OpenAI (gpt-5.1): Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-5.1 in organization org-hnKFObuxgiWnOQU9Y1DqflGF on requests per min (RPM): Limit 
2025-11-26 16:40:45,276 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:40:45,277 - __main__ - INFO - [OpenAI] Trying model: gpt-4o
2025-11-26 16:40:51,860 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-26 16:40:51,868 - __main__ - INFO -  Successfully generated content using OpenAI (gpt-4o)
2025-11-26 16:40:51,868 - __main__ - INFO - [regenerate_1764155417_f7979abf] Successfully completed regeneration: regen_simplify_vocabulary
2025-11-26 16:40:51,868 - __main__ - INFO - Job regenerate_1764155417_f7979abf: completed
2025-11-26 16:40:51,871 - __main__ - INFO - Job regenerate_1764155451_bfbaed2c: processing
2025-11-26 16:40:51,871 - __main__ - INFO - [regenerate_1764155451_bfbaed2c] Running regeneration prompt: regen_dedup using OPENAI
2025-11-26 16:40:52,038 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:40:52,038 - __main__ - INFO - [OpenAI] Trying model: gpt-5.1
2025-11-26 16:40:52,395 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:40:52,396 - openai._base_client - INFO - Retrying request to /chat/completions in 19.200000 seconds
2025-11-26 16:40:53,905 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-26 16:40:53,912 - __main__ - INFO -  Successfully generated content using OpenAI (gpt-4o)
2025-11-26 16:40:53,912 - __main__ - INFO - [regenerate_1764155419_a4c38e01] Successfully completed regeneration: regen_mcq_sync
2025-11-26 16:40:53,912 - __main__ - INFO - Job regenerate_1764155419_a4c38e01: completed
2025-11-26 16:40:53,915 - __main__ - INFO - Job regenerate_1764155453_87609edb: processing
2025-11-26 16:40:53,915 - __main__ - INFO - [regenerate_1764155453_87609edb] Running regeneration prompt: regen_remove_hallucination using OPENAI
2025-11-26 16:40:54,078 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:40:54,078 - __main__ - INFO - [OpenAI] Trying model: gpt-5.1
2025-11-26 16:40:54,395 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:40:54,396 - openai._base_client - INFO - Retrying request to /chat/completions in 16.002000 seconds
2025-11-26 16:41:10,741 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:41:10,742 - openai._base_client - INFO - Retrying request to /chat/completions in 5.730000 seconds
2025-11-26 16:41:11,949 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:41:11,950 - openai._base_client - INFO - Retrying request to /chat/completions in 7.710000 seconds
2025-11-26 16:41:16,810 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:41:16,811 - __main__ - WARNING - [OpenAI] gpt-5.1 via chat.completions failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-5.1 in organization org-hnKFObux
2025-11-26 16:41:16,811 - __main__ - WARNING - [OpenAI] gpt-5.1 via responses API also failed: AsyncResponses.create() got an unexpected keyword argument 'response_format'
2025-11-26 16:41:16,811 - __main__ - WARNING -  OpenAI (gpt-5.1): Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-5.1 in organization org-hnKFObuxgiWnOQU9Y1DqflGF on requests per min (RPM): Limit 
2025-11-26 16:41:16,971 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:41:16,971 - __main__ - INFO - [OpenAI] Trying model: gpt-4o
2025-11-26 16:41:20,003 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:41:20,005 - __main__ - WARNING - [OpenAI] gpt-5.1 via chat.completions failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-5.1 in organization org-hnKFObux
2025-11-26 16:41:20,005 - __main__ - WARNING - [OpenAI] gpt-5.1 via responses API also failed: AsyncResponses.create() got an unexpected keyword argument 'response_format'
2025-11-26 16:41:20,005 - __main__ - WARNING -  OpenAI (gpt-5.1): Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-5.1 in organization org-hnKFObuxgiWnOQU9Y1DqflGF on tokens per min (TPM): Limit 10
2025-11-26 16:41:20,167 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:41:20,168 - __main__ - INFO - [OpenAI] Trying model: gpt-4o
2025-11-26 16:41:20,480 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:41:20,481 - openai._base_client - INFO - Retrying request to /chat/completions in 10.446000 seconds
2025-11-26 16:41:23,023 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-26 16:41:23,029 - __main__ - INFO -  Successfully generated content using OpenAI (gpt-4o)
2025-11-26 16:41:23,029 - __main__ - INFO - [regenerate_1764155453_87609edb] Successfully completed regeneration: regen_remove_hallucination
2025-11-26 16:41:23,029 - __main__ - INFO - Job regenerate_1764155453_87609edb: completed
2025-11-26 16:41:23,033 - __main__ - INFO - Job regenerate_1764155483_f7979abf: processing
2025-11-26 16:41:23,033 - __main__ - INFO - [regenerate_1764155483_f7979abf] Running regeneration prompt: regen_simplify_vocabulary using OPENAI
2025-11-26 16:41:23,193 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:41:23,193 - __main__ - INFO - [OpenAI] Trying model: gpt-5.1
2025-11-26 16:41:23,493 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:41:23,494 - openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2025-11-26 16:41:31,273 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:41:31,274 - openai._base_client - INFO - Retrying request to /chat/completions in 2.838000 seconds
2025-11-26 16:41:34,415 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:41:34,416 - __main__ - WARNING - [OpenAI] gpt-4o via chat.completions failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-hnKFObuxg
2025-11-26 16:41:34,417 - __main__ - WARNING - [OpenAI] gpt-4o via responses API also failed: AsyncResponses.create() got an unexpected keyword argument 'response_format'
2025-11-26 16:41:34,417 - __main__ - WARNING -  OpenAI (gpt-4o): Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-hnKFObuxgiWnOQU9Y1DqflGF on requests per min (RPM): Limit 3
2025-11-26 16:41:34,418 - __main__ - WARNING -  All OpenAI models failed. Attempting Gemini fallback...
2025-11-26 16:41:35,289 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-26 16:41:35,289 - __main__ - INFO - [Gemini] Using model: gemini-2.0-flash-001
2025-11-26 16:41:41,214 - __main__ - INFO -  Successfully generated content using fallback Gemini
2025-11-26 16:41:41,216 - __main__ - INFO - [regenerate_1764155451_bfbaed2c] Successfully completed regeneration: regen_dedup
2025-11-26 16:41:41,217 - __main__ - INFO - Job regenerate_1764155451_bfbaed2c: completed
2025-11-26 16:41:41,268 - __main__ - INFO - Job regenerate_1764155501_a344ece3: processing
2025-11-26 16:41:41,269 - __main__ - INFO - [regenerate_1764155501_a344ece3] Running regeneration prompt: regen_tone_fix using OPENAI
2025-11-26 16:41:42,413 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:41:42,415 - __main__ - INFO - [OpenAI] Trying model: gpt-5.1
2025-11-26 16:41:42,789 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-26 16:41:42,792 - __main__ - WARNING - [OpenAI] gpt-5.1 via chat.completions failed: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with t
2025-11-26 16:41:42,793 - __main__ - WARNING - [OpenAI] gpt-5.1 via responses API also failed: AsyncResponses.create() got an unexpected keyword argument 'response_format'
2025-11-26 16:41:42,794 - __main__ - WARNING -  OpenAI (gpt-5.1): Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 
2025-11-26 16:41:43,973 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:41:43,975 - __main__ - INFO - [OpenAI] Trying model: gpt-4o
2025-11-26 16:41:44,371 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:41:44,372 - openai._base_client - INFO - Retrying request to /chat/completions in 9.372000 seconds
2025-11-26 16:41:44,392 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:41:44,394 - openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2025-11-26 16:41:54,860 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-26 16:41:54,861 - __main__ - WARNING - [OpenAI] gpt-5.1 via chat.completions failed: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with t
2025-11-26 16:41:54,862 - __main__ - WARNING - [OpenAI] gpt-5.1 via responses API also failed: AsyncResponses.create() got an unexpected keyword argument 'response_format'
2025-11-26 16:41:54,863 - __main__ - WARNING -  OpenAI (gpt-5.1): Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 
2025-11-26 16:41:56,030 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:41:56,032 - __main__ - INFO - [OpenAI] Trying model: gpt-4o
2025-11-26 16:42:04,790 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:42:04,792 - openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2025-11-26 16:42:08,808 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-26 16:42:08,811 - __main__ - INFO -  Successfully generated content using OpenAI (gpt-4o)
2025-11-26 16:42:08,812 - __main__ - INFO - [regenerate_1764155483_f7979abf] Successfully completed regeneration: regen_simplify_vocabulary
2025-11-26 16:42:08,812 - __main__ - INFO - Job regenerate_1764155483_f7979abf: completed
2025-11-26 16:42:08,820 - __main__ - INFO - Job regenerate_1764155528_bfbaed2c: processing
2025-11-26 16:42:08,821 - __main__ - INFO - [regenerate_1764155528_bfbaed2c] Running regeneration prompt: regen_dedup using OPENAI
2025-11-26 16:42:09,961 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:42:09,962 - __main__ - INFO - [OpenAI] Trying model: gpt-5.1
2025-11-26 16:42:10,332 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-26 16:42:10,334 - __main__ - WARNING - [OpenAI] gpt-5.1 via chat.completions failed: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with t
2025-11-26 16:42:10,335 - __main__ - WARNING - [OpenAI] gpt-5.1 via responses API also failed: AsyncResponses.create() got an unexpected keyword argument 'response_format'
2025-11-26 16:42:10,339 - __main__ - WARNING -  OpenAI (gpt-5.1): Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 
2025-11-26 16:42:11,578 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:42:11,579 - __main__ - INFO - [OpenAI] Trying model: gpt-4o
2025-11-26 16:42:11,936 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:42:11,940 - openai._base_client - INFO - Retrying request to /chat/completions in 2.934000 seconds
2025-11-26 16:42:15,180 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:42:15,181 - openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2025-11-26 16:42:25,148 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:42:25,151 - __main__ - WARNING - [OpenAI] gpt-4o via chat.completions failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-hnKFObuxg
2025-11-26 16:42:25,152 - __main__ - WARNING - [OpenAI] gpt-4o via responses API also failed: AsyncResponses.create() got an unexpected keyword argument 'response_format'
2025-11-26 16:42:25,152 - __main__ - WARNING -  OpenAI (gpt-4o): Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-hnKFObuxgiWnOQU9Y1DqflGF on tokens per min (TPM): Limit 100
2025-11-26 16:42:25,153 - __main__ - WARNING -  All OpenAI models failed. Attempting Gemini fallback...
2025-11-26 16:42:26,199 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-26 16:42:26,200 - __main__ - INFO - [Gemini] Using model: gemini-2.0-flash-001
2025-11-26 16:42:33,454 - __main__ - INFO -  Successfully generated content using fallback Gemini
2025-11-26 16:42:33,455 - __main__ - INFO - [regenerate_1764155501_a344ece3] Successfully completed regeneration: regen_tone_fix
2025-11-26 16:42:33,455 - __main__ - INFO - Job regenerate_1764155501_a344ece3: completed
2025-11-26 16:42:33,458 - __main__ - INFO - Job regenerate_1764155553_a344ece3: processing
2025-11-26 16:42:33,458 - __main__ - INFO - [regenerate_1764155553_a344ece3] Running regeneration prompt: regen_tone_fix using OPENAI
2025-11-26 16:42:33,625 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:42:33,625 - __main__ - INFO - [OpenAI] Trying model: gpt-5.1
2025-11-26 16:42:33,996 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:42:33,997 - openai._base_client - INFO - Retrying request to /chat/completions in 1.056000 seconds
2025-11-26 16:42:35,361 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:42:35,361 - openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2025-11-26 16:42:48,602 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-26 16:42:48,606 - __main__ - INFO -  Successfully generated content using OpenAI (gpt-4o)
2025-11-26 16:42:48,606 - __main__ - INFO - [regenerate_1764155528_bfbaed2c] Successfully completed regeneration: regen_dedup
2025-11-26 16:42:48,606 - __main__ - INFO - Job regenerate_1764155528_bfbaed2c: completed
2025-11-26 16:42:48,613 - __main__ - INFO - Job regenerate_1764155568_a344ece3: processing
2025-11-26 16:42:48,613 - __main__ - INFO - [regenerate_1764155568_a344ece3] Running regeneration prompt: regen_tone_fix using OPENAI
2025-11-26 16:42:48,781 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:42:48,781 - __main__ - INFO - [OpenAI] Trying model: gpt-5.1
2025-11-26 16:42:49,100 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:42:49,103 - openai._base_client - INFO - Retrying request to /chat/completions in 3.827000 seconds
2025-11-26 16:42:53,273 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:42:53,275 - openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2025-11-26 16:42:55,746 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:42:55,750 - __main__ - WARNING - [OpenAI] gpt-5.1 via chat.completions failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-5.1 in organization org-hnKFObux
2025-11-26 16:42:55,751 - __main__ - WARNING - [OpenAI] gpt-5.1 via responses API also failed: AsyncResponses.create() got an unexpected keyword argument 'response_format'
2025-11-26 16:42:55,752 - __main__ - WARNING -  OpenAI (gpt-5.1): Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-5.1 in organization org-hnKFObuxgiWnOQU9Y1DqflGF on tokens per min (TPM): Limit 10
2025-11-26 16:42:56,969 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:42:56,971 - __main__ - INFO - [OpenAI] Trying model: gpt-4o
2025-11-26 16:42:57,307 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:42:57,309 - openai._base_client - INFO - Retrying request to /chat/completions in 8.334000 seconds
2025-11-26 16:43:06,162 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:43:06,164 - openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2025-11-26 16:43:13,628 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-26 16:43:13,629 - __main__ - WARNING - [OpenAI] gpt-5.1 via chat.completions failed: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with t
2025-11-26 16:43:13,630 - __main__ - WARNING - [OpenAI] gpt-5.1 via responses API also failed: AsyncResponses.create() got an unexpected keyword argument 'response_format'
2025-11-26 16:43:13,630 - __main__ - WARNING -  OpenAI (gpt-5.1): Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 
2025-11-26 16:43:14,835 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:43:14,836 - __main__ - INFO - [OpenAI] Trying model: gpt-4o
2025-11-26 16:43:15,169 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:43:15,171 - openai._base_client - INFO - Retrying request to /chat/completions in 8.208000 seconds
2025-11-26 16:43:23,732 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:43:23,735 - openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2025-11-26 16:43:26,517 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:43:26,520 - __main__ - WARNING - [OpenAI] gpt-4o via chat.completions failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-hnKFObuxg
2025-11-26 16:43:26,521 - __main__ - WARNING - [OpenAI] gpt-4o via responses API also failed: AsyncResponses.create() got an unexpected keyword argument 'response_format'
2025-11-26 16:43:26,522 - __main__ - WARNING -  OpenAI (gpt-4o): Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-hnKFObuxgiWnOQU9Y1DqflGF on tokens per min (TPM): Limit 100
2025-11-26 16:43:26,522 - __main__ - WARNING -  All OpenAI models failed. Attempting Gemini fallback...
2025-11-26 16:43:27,455 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-26 16:43:27,455 - __main__ - INFO - [Gemini] Using model: gemini-2.0-flash-001
2025-11-26 16:43:33,484 - __main__ - INFO -  Successfully generated content using fallback Gemini
2025-11-26 16:43:33,484 - __main__ - INFO - [regenerate_1764155553_a344ece3] Successfully completed regeneration: regen_tone_fix
2025-11-26 16:43:33,485 - __main__ - INFO - Job regenerate_1764155553_a344ece3: completed
2025-11-26 16:43:33,489 - __main__ - INFO - Job regenerate_1764155613_87609edb: processing
2025-11-26 16:43:33,489 - __main__ - INFO - [regenerate_1764155613_87609edb] Running regeneration prompt: regen_remove_hallucination using OPENAI
2025-11-26 16:43:33,647 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:43:33,648 - __main__ - INFO - [OpenAI] Trying model: gpt-5.1
2025-11-26 16:43:34,008 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:43:34,009 - openai._base_client - INFO - Retrying request to /chat/completions in 2.454000 seconds
2025-11-26 16:43:36,756 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:43:36,756 - openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2025-11-26 16:43:52,292 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-26 16:43:52,299 - __main__ - INFO -  Successfully generated content using OpenAI (gpt-4o)
2025-11-26 16:43:52,299 - __main__ - INFO - [regenerate_1764155568_a344ece3] Successfully completed regeneration: regen_tone_fix
2025-11-26 16:43:52,300 - __main__ - INFO - Job regenerate_1764155568_a344ece3: completed
2025-11-26 16:43:52,302 - __main__ - INFO - Job regenerate_1764155632_a344ece3: processing
2025-11-26 16:43:52,302 - __main__ - INFO - [regenerate_1764155632_a344ece3] Running regeneration prompt: regen_tone_fix using OPENAI
2025-11-26 16:43:52,467 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:43:52,468 - __main__ - INFO - [OpenAI] Trying model: gpt-5.1
2025-11-26 16:43:52,795 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:43:52,796 - openai._base_client - INFO - Retrying request to /chat/completions in 6.042000 seconds
2025-11-26 16:43:57,117 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:43:57,119 - __main__ - WARNING - [OpenAI] gpt-5.1 via chat.completions failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-5.1 in organization org-hnKFObux
2025-11-26 16:43:57,119 - __main__ - WARNING - [OpenAI] gpt-5.1 via responses API also failed: AsyncResponses.create() got an unexpected keyword argument 'response_format'
2025-11-26 16:43:57,120 - __main__ - WARNING -  OpenAI (gpt-5.1): Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-5.1 in organization org-hnKFObuxgiWnOQU9Y1DqflGF on tokens per min (TPM): Limit 10
2025-11-26 16:43:58,372 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:43:58,374 - __main__ - INFO - [OpenAI] Trying model: gpt-4o
2025-11-26 16:43:58,711 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:43:58,713 - openai._base_client - INFO - Retrying request to /chat/completions in 11.658000 seconds
2025-11-26 16:43:59,176 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:43:59,185 - openai._base_client - INFO - Retrying request to /chat/completions in 20.000000 seconds
2025-11-26 16:44:16,683 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-26 16:44:16,695 - __main__ - INFO -  Successfully generated content using OpenAI (gpt-4o)
2025-11-26 16:44:16,696 - __main__ - INFO - [regenerate_1764155613_87609edb] Successfully completed regeneration: regen_remove_hallucination
2025-11-26 16:44:16,697 - __main__ - INFO - Job regenerate_1764155613_87609edb: completed
2025-11-26 16:44:19,547 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:44:19,549 - __main__ - WARNING - [OpenAI] gpt-5.1 via chat.completions failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-5.1 in organization org-hnKFObux
2025-11-26 16:44:19,550 - __main__ - WARNING - [OpenAI] gpt-5.1 via responses API also failed: AsyncResponses.create() got an unexpected keyword argument 'response_format'
2025-11-26 16:44:19,551 - __main__ - WARNING -  OpenAI (gpt-5.1): Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-5.1 in organization org-hnKFObuxgiWnOQU9Y1DqflGF on tokens per min (TPM): Limit 10
2025-11-26 16:44:20,779 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:44:20,780 - __main__ - INFO - [OpenAI] Trying model: gpt-4o
2025-11-26 16:44:21,115 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:44:21,117 - openai._base_client - INFO - Retrying request to /chat/completions in 13.464000 seconds
2025-11-26 16:44:49,880 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-26 16:44:49,884 - __main__ - INFO -  Successfully generated content using OpenAI (gpt-4o)
2025-11-26 16:44:49,885 - __main__ - INFO - [regenerate_1764155632_a344ece3] Successfully completed regeneration: regen_tone_fix
2025-11-26 16:44:49,885 - __main__ - INFO - Job regenerate_1764155632_a344ece3: completed
2025-11-26 16:44:49,887 - __main__ - INFO - Job regenerate_1764155689_87609edb: processing
2025-11-26 16:44:49,887 - __main__ - INFO - [regenerate_1764155689_87609edb] Running regeneration prompt: regen_remove_hallucination using OPENAI
2025-11-26 16:44:50,050 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:44:50,050 - __main__ - INFO - [OpenAI] Trying model: gpt-5.1
2025-11-26 16:44:50,450 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-26 16:44:50,451 - __main__ - WARNING - [OpenAI] gpt-5.1 via chat.completions failed: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with t
2025-11-26 16:44:50,451 - __main__ - WARNING - [OpenAI] gpt-5.1 via responses API also failed: AsyncResponses.create() got an unexpected keyword argument 'response_format'
2025-11-26 16:44:50,451 - __main__ - WARNING -  OpenAI (gpt-5.1): Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 
2025-11-26 16:44:50,616 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:44:50,616 - __main__ - INFO - [OpenAI] Trying model: gpt-4o
2025-11-26 16:44:50,929 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-11-26 16:44:50,929 - openai._base_client - INFO - Retrying request to /chat/completions in 9.006000 seconds
2025-11-26 16:45:04,763 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-26 16:45:04,764 - __main__ - INFO -  Successfully generated content using OpenAI (gpt-4o)
2025-11-26 16:45:04,765 - __main__ - INFO - [regenerate_1764155689_87609edb] Successfully completed regeneration: regen_remove_hallucination
2025-11-26 16:45:04,765 - __main__ - INFO - Job regenerate_1764155689_87609edb: completed
2025-11-26 16:49:40,755 - __main__ - INFO - [SHUTDOWN] LLM Service shutting down
2025-11-26 16:50:02,129 - __main__ - INFO - [AUTO MODE] Primary: OpenAI GPT-4o | Fallback: Gemini 2.0 Flash
2025-11-26 16:50:02,351 - __main__ - INFO - [OK] OpenAI API configured successfully
2025-11-26 16:50:03,362 - __main__ - INFO - [OK] Gemini API configured and validated successfully
2025-11-26 16:50:03,363 - __main__ - INFO - [OK] All systems operational
